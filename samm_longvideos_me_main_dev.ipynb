{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A jupyter notebook version file for the `main.py`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `autoreload` to execute the change in `.py` files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds_path: D:\\Databases\\SAMM_longvideos\\preds\\me_vit_b_batch_size_48_epochs_25_pseudo_labeling_128.pkl\n"
     ]
    }
   ],
   "source": [
    "import _pickle\n",
    "import natsort\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "dataset_dir = \"D:/Databases/SAMM_longvideos\"\n",
    "# dataset_dir = \"F:/HEH/Databases/SAMM_longvideos\"\n",
    "# dataset_dir = \"/data/disk1/heh/databases/SAMM_longvideos\"\n",
    "\n",
    "images_loading = False\n",
    "image_size = 128\n",
    "load_cropped_images = False\n",
    "# expression_type = \"mae\"  # macro-expression spotting\n",
    "expression_type = \"me\"  # micro-expression spotting\n",
    "save_x = False\n",
    "debug_preds = True\n",
    "labeling_function = \"pseudo_labeling\"\n",
    "# labeling_function = \"original_labeling\"\n",
    "model_names = {\n",
    "    0: \"SOFTNet\",\n",
    "    1: \"SOFTNetCBAM\",\n",
    "    2: \"ViT-B\",\n",
    "    3: \"SL-ViT-B\",\n",
    "    4: \"Swin-T\",\n",
    "    5: \"Swin-S\",\n",
    "    6: \"L-Swin-T\",\n",
    "    7: \"S-Swin-T\",\n",
    "    8: \"SL-Swin-T\",\n",
    "    9: \"SL-Swin-S\",\n",
    "}\n",
    "model_name = model_names[2]\n",
    "batch_size = 48\n",
    "epochs = 25\n",
    "save_preds = False\n",
    "preds_stem = (\n",
    "    f\"{expression_type}_\"\n",
    "    + model_name.lower().replace(\"-\", \"_\")\n",
    "    + f\"_batch_size_{batch_size}\"\n",
    "    + f\"_epochs_{epochs}\"\n",
    "    + f\"_{labeling_function}\"\n",
    "    + f\"_{image_size}\"\n",
    "    # + \"_2\"\n",
    ")\n",
    "preds_path = Path(dataset_dir, \"preds\", preds_stem).with_suffix(\".pkl\")\n",
    "print(f\"preds_path: {preds_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing import *\n",
    "\n",
    "# crop_images_dev(dataset_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When debug the image processing, the videos_images is from cropped_rawpic, whereas the other variables are from rawpic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_video: 006_1\n",
      "subject_video: 006_2\n",
      "subject_video: 006_3\n",
      "subject_video: 006_4\n",
      "subject_video: 006_5\n",
      "subject_video: 006_6\n",
      "subject_video: 006_7\n",
      "subject_video: 007_3\n",
      "subject_video: 007_4\n",
      "subject_video: 007_5\n",
      "subject_video: 007_6\n",
      "subject_video: 007_7\n",
      "subject_video: 008_1\n",
      "subject_video: 008_5\n",
      "subject_video: 008_6\n",
      "subject_video: 008_7\n",
      "subject_video: 009_2\n",
      "subject_video: 009_3\n",
      "subject_video: 009_4\n",
      "subject_video: 009_6\n",
      "subject_video: 009_7\n",
      "subject_video: 010_1\n",
      "subject_video: 010_2\n",
      "subject_video: 010_3\n",
      "subject_video: 010_4\n",
      "subject_video: 010_5\n",
      "subject_video: 010_6\n",
      "subject_video: 010_7\n",
      "subject_video: 011_1\n",
      "subject_video: 011_2\n",
      "subject_video: 011_3\n",
      "subject_video: 011_4\n",
      "subject_video: 011_5\n",
      "subject_video: 011_6\n",
      "subject_video: 011_7\n",
      "subject_video: 012_3\n",
      "subject_video: 012_4\n",
      "subject_video: 012_5\n",
      "subject_video: 012_6\n",
      "subject_video: 012_7\n",
      "subject_video: 013_1\n",
      "subject_video: 013_2\n",
      "subject_video: 013_3\n",
      "subject_video: 013_6\n",
      "subject_video: 013_7\n",
      "subject_video: 014_1\n",
      "subject_video: 014_2\n",
      "subject_video: 014_3\n",
      "subject_video: 014_4\n",
      "subject_video: 014_5\n",
      "subject_video: 014_6\n",
      "subject_video: 014_7\n",
      "subject_video: 015_1\n",
      "subject_video: 015_3\n",
      "subject_video: 015_5\n",
      "subject_video: 015_6\n",
      "subject_video: 015_7\n",
      "subject_video: 016_1\n",
      "subject_video: 016_2\n",
      "subject_video: 016_4\n",
      "subject_video: 016_5\n",
      "subject_video: 016_6\n",
      "subject_video: 016_7\n",
      "subject_video: 017_1\n",
      "subject_video: 017_2\n",
      "subject_video: 017_3\n",
      "subject_video: 017_4\n",
      "subject_video: 017_5\n",
      "subject_video: 017_6\n",
      "subject_video: 018_1\n",
      "subject_video: 018_2\n",
      "subject_video: 018_3\n",
      "subject_video: 018_4\n",
      "subject_video: 018_5\n",
      "subject_video: 018_6\n",
      "subject_video: 018_7\n",
      "subject_video: 019_1\n",
      "subject_video: 019_2\n",
      "subject_video: 019_3\n",
      "subject_video: 019_4\n",
      "subject_video: 019_5\n",
      "subject_video: 019_7\n",
      "subject_video: 020_1\n",
      "subject_video: 020_2\n",
      "subject_video: 020_3\n",
      "subject_video: 020_4\n",
      "subject_video: 020_5\n",
      "subject_video: 020_6\n",
      "subject_video: 020_7\n",
      "subject_video: 021_3\n",
      "subject_video: 021_7\n",
      "subject_video: 022_2\n",
      "subject_video: 022_3\n",
      "subject_video: 022_4\n",
      "subject_video: 022_5\n",
      "subject_video: 022_6\n",
      "subject_video: 023_1\n",
      "subject_video: 023_4\n",
      "subject_video: 024_2\n",
      "subject_video: 024_3\n",
      "subject_video: 024_5\n",
      "subject_video: 025_3\n",
      "subject_video: 025_4\n",
      "subject_video: 025_5\n",
      "subject_video: 025_6\n",
      "subject_video: 026_1\n",
      "subject_video: 026_2\n",
      "subject_video: 026_3\n",
      "subject_video: 026_5\n",
      "subject_video: 026_6\n",
      "subject_video: 026_7\n",
      "subject_video: 028_4\n",
      "subject_video: 030_1\n",
      "subject_video: 030_2\n",
      "subject_video: 030_5\n",
      "subject_video: 031_3\n",
      "subject_video: 032_2\n",
      "subject_video: 032_3\n",
      "subject_video: 032_4\n",
      "subject_video: 032_5\n",
      "subject_video: 032_6\n",
      "subject_video: 033_1\n",
      "subject_video: 033_2\n",
      "subject_video: 033_3\n",
      "subject_video: 033_4\n",
      "subject_video: 033_5\n",
      "subject_video: 033_6\n",
      "subject_video: 033_7\n",
      "subject_video: 034_3\n",
      "subject_video: 034_6\n",
      "subject_video: 034_7\n",
      "subject_video: 035_1\n",
      "subject_video: 035_2\n",
      "subject_video: 035_3\n",
      "subject_video: 035_4\n",
      "subject_video: 035_5\n",
      "subject_video: 035_6\n",
      "subject_video: 035_7\n",
      "subject_video: 036_2\n",
      "subject_video: 036_4\n",
      "subject_video: 036_6\n",
      "subject_video: 036_7\n",
      "subject_video: 037_2\n",
      "subject_video: 037_3\n",
      "subject_video: 037_4\n",
      "subject_video: 037_5\n",
      "subject_video: 037_7\n"
     ]
    }
   ],
   "source": [
    "from image_processing import *\n",
    "\n",
    "# videos_images, subjects, subjects_videos_code = load_images(dataset_dir)\n",
    "\n",
    "videos_images, subjects, subjects_videos_code = load_images_dev(\n",
    "    dataset_dir,\n",
    "    images_loading=images_loading,\n",
    "    image_size=image_size,\n",
    "    load_cropped_images=load_cropped_images,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects: ['006', '007', '008', '009', '010', '011', '012', '013', '014', '015', '016', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '028', '030', '031', '032', '033', '034', '035', '036', '037']\n",
      "subjects_videos_code: [['1', '2', '3', '4', '5', '6', '7'], ['3', '4', '5', '6', '7'], ['1', '5', '6', '7'], ['2', '3', '4', '6', '7'], ['1', '2', '3', '4', '5', '6', '7'], ['1', '2', '3', '4', '5', '6', '7'], ['3', '4', '5', '6', '7'], ['1', '2', '3', '6', '7'], ['1', '2', '3', '4', '5', '6', '7'], ['1', '3', '5', '6', '7'], ['1', '2', '4', '5', '6', '7'], ['1', '2', '3', '4', '5', '6'], ['1', '2', '3', '4', '5', '6', '7'], ['1', '2', '3', '4', '5', '7'], ['1', '2', '3', '4', '5', '6', '7'], ['3', '7'], ['2', '3', '4', '5', '6'], ['1', '4'], ['2', '3', '5'], ['3', '4', '5', '6'], ['1', '2', '3', '5', '6', '7'], ['4'], ['1', '2', '5'], ['3'], ['2', '3', '4', '5', '6'], ['1', '2', '3', '4', '5', '6', '7'], ['3', '6', '7'], ['1', '2', '3', '4', '5', '6', '7'], ['2', '4', '6', '7'], ['2', '3', '4', '5', '7']]\n"
     ]
    }
   ],
   "source": [
    "print(\"subjects:\", subjects)\n",
    "print(\"subjects_videos_code:\", subjects_videos_code)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Excel \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Columns: Index(['subject', 'Filename', 'video_code', 'onset', 'apex', 'offset',\n",
      "       'Duration', 'expression_type', 'Action Units', 'Notes',\n",
      "       'subject_video_code', 'subject_code'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from label_processing import load_excel\n",
    "\n",
    "Excel_data = load_excel(dataset_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>Filename</th>\n",
       "      <th>video_code</th>\n",
       "      <th>onset</th>\n",
       "      <th>apex</th>\n",
       "      <th>offset</th>\n",
       "      <th>Duration</th>\n",
       "      <th>expression_type</th>\n",
       "      <th>Action Units</th>\n",
       "      <th>Notes</th>\n",
       "      <th>subject_video_code</th>\n",
       "      <th>subject_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>006</td>\n",
       "      <td>006_1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>566</td>\n",
       "      <td>648</td>\n",
       "      <td>743</td>\n",
       "      <td>178</td>\n",
       "      <td>Macro</td>\n",
       "      <td>4(B/C)+7B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006_1</td>\n",
       "      <td>006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006</td>\n",
       "      <td>006_1_2</td>\n",
       "      <td>1</td>\n",
       "      <td>3562</td>\n",
       "      <td>3588</td>\n",
       "      <td>3632</td>\n",
       "      <td>71</td>\n",
       "      <td>Micro - 1/2</td>\n",
       "      <td>4+7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006_1</td>\n",
       "      <td>006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006</td>\n",
       "      <td>006_1_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1912</td>\n",
       "      <td>1948</td>\n",
       "      <td>1988</td>\n",
       "      <td>77</td>\n",
       "      <td>Micro - 1/2</td>\n",
       "      <td>4</td>\n",
       "      <td>While blinking</td>\n",
       "      <td>006_1</td>\n",
       "      <td>006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>006</td>\n",
       "      <td>006_1_4</td>\n",
       "      <td>1</td>\n",
       "      <td>324</td>\n",
       "      <td>368</td>\n",
       "      <td>403</td>\n",
       "      <td>80</td>\n",
       "      <td>Micro - 1/2</td>\n",
       "      <td>4+7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006_1</td>\n",
       "      <td>006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006</td>\n",
       "      <td>006_1_5</td>\n",
       "      <td>1</td>\n",
       "      <td>3343</td>\n",
       "      <td>3388</td>\n",
       "      <td>3424</td>\n",
       "      <td>82</td>\n",
       "      <td>Micro - 1/2</td>\n",
       "      <td>4+7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>006_1</td>\n",
       "      <td>006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject Filename video_code onset  apex offset Duration expression_type   \n",
       "0     006  006_1_1          1   566   648    743      178           Macro  \\\n",
       "1     006  006_1_2          1  3562  3588   3632       71     Micro - 1/2   \n",
       "2     006  006_1_3          1  1912  1948   1988       77     Micro - 1/2   \n",
       "3     006  006_1_4          1   324   368    403       80     Micro - 1/2   \n",
       "4     006  006_1_5          1  3343  3388   3424       82     Micro - 1/2   \n",
       "\n",
       "  Action Units           Notes subject_video_code subject_code  \n",
       "0    4(B/C)+7B             NaN              006_1          006  \n",
       "1          4+7             NaN              006_1          006  \n",
       "2            4  While blinking              006_1          006  \n",
       "3          4+7             NaN              006_1          006  \n",
       "4          4+7             NaN              006_1          006  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Excel_data.head(5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Ground Truth Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required_videos_index:  [0, 1, 2, 4, 7, 8, 9, 10, 11, 16, 17, 22, 24, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 44, 45, 46, 47, 49, 50, 51, 54, 62, 65, 68, 69, 71, 73, 75, 78, 79, 80, 82, 85, 88, 90, 91, 92, 93, 94, 96, 98, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 117, 118, 120, 121, 122, 128, 130, 131, 134, 135, 136, 137, 141, 143, 144]\n",
      "len(clean_videos_images) = 79\n"
     ]
    }
   ],
   "source": [
    "from label_processing import load_ground_truth_labels\n",
    "\n",
    "\n",
    "(\n",
    "    clean_videos_images,\n",
    "    clean_subjects_videos_code,\n",
    "    clean_subjects,\n",
    "    clean_subjects_videos_ground_truth_labels,\n",
    ") = load_ground_truth_labels(\n",
    "    dataset_dir,\n",
    "    expression_type,\n",
    "    videos_images,\n",
    "    subjects_videos_code,\n",
    "    subjects,\n",
    "    Excel_data,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(clean_subjects):  29\n",
      "clean_subjects:  ['006' '007' '009' '010' '011' '012' '013' '014' '015' '016' '017' '018'\n",
      " '019' '020' '021' '022' '023' '024' '025' '026' '028' '030' '031' '032'\n",
      " '033' '034' '035' '036' '037']\n",
      "len(clean_subjects_videos_code):  29\n",
      "clean_subjects_videos_codes:  [['1', '2', '3', '5'], ['3', '4', '5', '6', '7'], ['2', '3'], ['2', '4'], ['1', '2', '3', '4', '5', '6', '7'], ['3', '7'], ['1', '7'], ['1', '2', '3', '5', '6', '7'], ['5'], ['7'], ['3', '6'], ['1', '3', '5', '7'], ['3', '4', '5'], ['1', '4', '7'], ['7'], ['2', '3', '4', '5'], ['1'], ['2'], ['4', '5', '6'], ['1', '2', '3', '5', '6', '7'], ['4'], ['1', '5'], ['3'], ['3', '4', '6'], ['1', '2'], ['3', '7'], ['1', '4', '5', '6', '7'], ['7'], ['3', '4']]\n",
      "len(clean_subjects_videos_ground_truth_labels):  29\n",
      "clean_subjects_videos_ground_truth_labels:  [[[[3561, 3631], [1911, 1987], [323, 402], [3342, 3423], [5159, 5258]], [[79, 173]], [[138, 201], [1286, 1355]], [[1135, 1213], [1829, 1925], [4957, 5050]]], [[[245, 290]], [[299, 398]], [[258, 334], [2932, 3031]], [[396, 440], [1195, 1276], [2459, 2516], [548, 622]], [[6729, 6769], [253, 336]]], [[[576, 640]], [[1355, 1431], [1467, 1544], [2833, 2918]]], [[[191, 227], [1210, 1287]], [[527, 556], [3707, 3737]]], [[[3079, 3167]], [[2028, 2067], [2068, 2124], [3884, 3973], [3360, 3448]], [[362, 410], [840, 919], [943, 1030], [1207, 1307]], [[6749, 6802], [4157, 4253], [2754, 2852], [2979, 3036]], [[1047, 1087]], [[4421, 4485], [4522, 4618], [2503, 2601], [2606, 2679]], [[1219, 1268], [3598, 3679]]], [[[4620, 4675], [4696, 4795]], [[870, 922]]], [[[3801, 3889], [4489, 4581], [705, 801], [840, 918], [5657, 5738]], [[2076, 2166]]], [[[2356, 2397], [666, 752]], [[4615, 4704], [3873, 3967]], [[1634, 1713], [425, 522]], [[468, 556]], [[1315, 1349], [1189, 1252], [127, 195]], [[3528, 3597]]], [[[879, 941], [1086, 1158], [549, 626]]], [[[1274, 1322], [2839, 2891], [3394, 3446], [5119, 5206], [11255, 11348]]], [[[311, 386], [82, 164], [1392, 1491], [173, 263]], [[606, 677], [415, 507]]], [[[520, 606]], [[1404, 1499]], [[5490, 5559]], [[132, 174]]], [[[371, 470]], [[495, 549]], [[1226, 1307]]], [[[2303, 2336], [2227, 2282], [6750, 6824], [7613, 7708]], [[3439, 3496], [1481, 1527]], [[8517, 8576], [9070, 9164], [146, 237]]], [[[3588, 3645], [852, 941]]], [[[401, 500]], [[379, 427], [3658, 3696]], [[491, 568]], [[334, 404]]], [[[523, 573]]], [[[762, 834]]], [[[2827, 2907], [615, 701]], [[839, 936]], [[821, 895]]], [[[294, 369], [116, 202]], [[2880, 2946], [2951, 3027], [2606, 2684], [4014, 4097]], [[1703, 1736], [3581, 3639]], [[572, 645]], [[347, 440]], [[1847, 1946], [4578, 4653], [1749, 1843]]], [[[1070, 1133], [369, 440], [1287, 1375]]], [[[378, 459], [4343, 4433]], [[420, 500]]], [[[330, 385]]], [[[1895, 1969], [2125, 2206], [424, 468]], [[3306, 3370], [407, 478]], [[306, 365]]], [[[956, 1008], [1540, 1608], [1888, 1972]], [[694, 775], [2116, 2214]]], [[[128, 216]], [[1577, 1654], [3635, 3718]]], [[[648, 690]], [[230, 262], [1508, 1573]], [[407, 467], [2408, 2472], [252, 340]], [[179, 235]], [[7808, 7852], [822, 917]]], [[[2263, 2362]]], [[[3305, 3381], [3195, 3294]], [[1487, 1576]]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"len(clean_subjects): \", len(clean_subjects))\n",
    "print(\"clean_subjects: \", clean_subjects)\n",
    "print(\"len(clean_subjects_videos_code): \", len(clean_subjects_videos_code))\n",
    "print(\"clean_subjects_videos_codes: \", clean_subjects_videos_code)\n",
    "print(\n",
    "    \"len(clean_subjects_videos_ground_truth_labels): \",\n",
    "    len(clean_subjects_videos_ground_truth_labels),\n",
    ")\n",
    "print(\n",
    "    \"clean_subjects_videos_ground_truth_labels: \",\n",
    "    clean_subjects_videos_ground_truth_labels,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 006 ['1', '2', '3', '5'] 4\n",
      "1 007 ['3', '4', '5', '6', '7'] 9\n",
      "2 009 ['2', '3'] 11\n",
      "3 010 ['2', '4'] 13\n",
      "4 011 ['1', '2', '3', '4', '5', '6', '7'] 20\n",
      "5 012 ['3', '7'] 22\n",
      "6 013 ['1', '7'] 24\n",
      "7 014 ['1', '2', '3', '5', '6', '7'] 30\n",
      "8 015 ['5'] 31\n",
      "9 016 ['7'] 32\n",
      "10 017 ['3', '6'] 34\n",
      "11 018 ['1', '3', '5', '7'] 38\n",
      "12 019 ['3', '4', '5'] 41\n",
      "13 020 ['1', '4', '7'] 44\n",
      "14 021 ['7'] 45\n",
      "15 022 ['2', '3', '4', '5'] 49\n",
      "16 023 ['1'] 50\n",
      "17 024 ['2'] 51\n",
      "18 025 ['4', '5', '6'] 54\n",
      "19 026 ['1', '2', '3', '5', '6', '7'] 60\n",
      "20 028 ['4'] 61\n",
      "21 030 ['1', '5'] 63\n",
      "22 031 ['3'] 64\n",
      "23 032 ['3', '4', '6'] 67\n",
      "24 033 ['1', '2'] 69\n",
      "25 034 ['3', '7'] 71\n",
      "26 035 ['1', '4', '5', '6', '7'] 76\n",
      "27 036 ['7'] 77\n",
      "28 037 ['3', '4'] 79\n"
     ]
    }
   ],
   "source": [
    "clean_subjects_videos_code_len = 0\n",
    "for i, clean_subject_videos_code in enumerate(clean_subjects_videos_code):\n",
    "    clean_subjects_videos_code_len += len(clean_subject_videos_code)\n",
    "    print(\n",
    "        i,\n",
    "        clean_subjects[i],\n",
    "        clean_subjects_videos_code[i],\n",
    "        clean_subjects_videos_code_len,\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k (Half of average length of expression) =  37\n"
     ]
    }
   ],
   "source": [
    "from label_processing import calculate_k\n",
    "\n",
    "k = calculate_k(clean_subjects_videos_ground_truth_labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about 1034 m.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Optical Flow Features (shape = [128, 128, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features_extraction import extract_features\n",
    "\n",
    "# clean_videos_images_features = extract_features(clean_videos_images, k, image_size=128)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes 908 m.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_processing import pre_process\n",
    "\n",
    "# resampled_clean_videos_images_features = pre_process(\n",
    "#     clean_videos_images, clean_videos_images_features, k\n",
    "# )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump Resampled Clean Videos Images Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\n",
    "#     Path(\n",
    "#         dataset_dir,\n",
    "#         f\"resampled_clean_videos_images_{expression_type}_features_{image_size}\",\n",
    "#     ).with_suffix(\".pkl\"),\n",
    "#     \"wb\",\n",
    "# ) as pkl_file:\n",
    "#     _pickle.dump(resampled_clean_videos_images_features, pkl_file)\n",
    "#     pkl_file.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load **Original** Resampled Clean Videos Images Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\n",
    "#     Path(\n",
    "#         dataset_dir,\n",
    "#         f\"original_resampled_clean_videos_images_{expression_type}_features.pkl\",\n",
    "#     ),\n",
    "#     \"rb\",\n",
    "# ) as pkl_file:\n",
    "#     resampled_clean_videos_images_features = _pickle.load(pkl_file)\n",
    "#     pkl_file.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Resampled Clean Videos Images Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_x is not False and debug_preds is not True:\n",
    "    with open(\n",
    "        Path(\n",
    "            dataset_dir,\n",
    "            f\"resampled_clean_videos_images_{expression_type}_features_{image_size}\",\n",
    "        ).with_suffix(\".pkl\"),\n",
    "        \"rb\",\n",
    "    ) as pkl_file:\n",
    "        resampled_clean_videos_images_features = _pickle.load(pkl_file)\n",
    "        pkl_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_x is not False and debug_preds is not True:\n",
    "    print(\n",
    "        \"len(resampled_clean_videos_images_features): \",\n",
    "        len(resampled_clean_videos_images_features),\n",
    "    )\n",
    "    print(\n",
    "        \"len(resampled_clean_videos_images_features[0]): \",\n",
    "        len(resampled_clean_videos_images_features[0]),\n",
    "    )\n",
    "    print(\n",
    "        \"resampled_clean_videos_images_features[0][0].shape: \",\n",
    "        resampled_clean_videos_images_features[0][0].shape,\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo Labeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames: 310682\n"
     ]
    }
   ],
   "source": [
    "from labeling import *\n",
    "\n",
    "if labeling_function == \"pseudo_labeling\":\n",
    "    labels = get_pseudo_labels(\n",
    "        clean_videos_images, clean_subjects_videos_ground_truth_labels, k\n",
    "    )\n",
    "elif labeling_function == \"original_labeling\":\n",
    "    labels = get_original_labels(\n",
    "        clean_videos_images, clean_subjects_videos_ground_truth_labels, k\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for LOSO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Index for each subject:-\n",
      "\n",
      "subject 006 ( group = 0): 0 -> 19551\n",
      "subject 006 has 4 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  4\n",
      "\n",
      "subject 007 ( group = 1): 19551 -> 34566\n",
      "subject 007 has 5 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  9\n",
      "\n",
      "subject 009 ( group = 2): 34566 -> 38612\n",
      "subject 009 has 2 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  11\n",
      "\n",
      "subject 010 ( group = 3): 38612 -> 47425\n",
      "subject 010 has 2 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  13\n",
      "\n",
      "subject 011 ( group = 4): 47425 -> 90918\n",
      "subject 011 has 7 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  20\n",
      "\n",
      "subject 012 ( group = 5): 90918 -> 97820\n",
      "subject 012 has 2 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  22\n",
      "\n",
      "subject 013 ( group = 6): 97820 -> 114534\n",
      "subject 013 has 2 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  24\n",
      "\n",
      "subject 014 ( group = 7): 114534 -> 139833\n",
      "subject 014 has 6 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  30\n",
      "\n",
      "subject 015 ( group = 8): 139833 -> 141796\n",
      "subject 015 has 1 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  31\n",
      "\n",
      "subject 016 ( group = 9): 141796 -> 153529\n",
      "subject 016 has 1 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  32\n",
      "\n",
      "subject 017 ( group = 10): 153529 -> 157956\n",
      "subject 017 has 2 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  34\n",
      "\n",
      "subject 018 ( group = 11): 157956 -> 168187\n",
      "subject 018 has 4 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  38\n",
      "\n",
      "subject 019 ( group = 12): 168187 -> 175076\n",
      "subject 019 has 3 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  41\n",
      "\n",
      "subject 020 ( group = 13): 175076 -> 196604\n",
      "subject 020 has 3 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  44\n",
      "\n",
      "subject 021 ( group = 14): 196604 -> 201567\n",
      "subject 021 has 1 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  45\n",
      "\n",
      "subject 022 ( group = 15): 201567 -> 212655\n",
      "subject 022 has 4 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  49\n",
      "\n",
      "subject 023 ( group = 16): 212655 -> 213618\n",
      "subject 023 has 1 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  50\n",
      "\n",
      "subject 024 ( group = 17): 213618 -> 215283\n",
      "subject 024 has 1 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  51\n",
      "\n",
      "subject 025 ( group = 18): 215283 -> 221672\n",
      "subject 025 has 3 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  54\n",
      "\n",
      "subject 026 ( group = 19): 221672 -> 238346\n",
      "subject 026 has 6 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  60\n",
      "\n",
      "subject 028 ( group = 20): 238346 -> 240310\n",
      "subject 028 has 1 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  61\n",
      "\n",
      "subject 030 ( group = 21): 240310 -> 248736\n",
      "subject 030 has 2 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  63\n",
      "\n",
      "subject 031 ( group = 22): 248736 -> 249353\n",
      "subject 031 has 1 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  64\n",
      "\n",
      "subject 032 ( group = 23): 249353 -> 258037\n",
      "subject 032 has 3 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  67\n",
      "\n",
      "subject 033 ( group = 24): 258037 -> 267659\n",
      "subject 033 has 2 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  69\n",
      "\n",
      "subject 034 ( group = 25): 267659 -> 272086\n",
      "subject 034 has 2 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  71\n",
      "\n",
      "subject 035 ( group = 26): 272086 -> 293538\n",
      "subject 035 has 5 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  76\n",
      "\n",
      "subject 036 ( group = 27): 293538 -> 301702\n",
      "subject 036 has 1 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  77\n",
      "\n",
      "subject 037 ( group = 28): 301702 -> 310682\n",
      "subject 037 has 2 clean video(s)\n",
      "sum clean_subject_videos_ground_truth_labels_len:  79\n"
     ]
    }
   ],
   "source": [
    "from loso_preparing import prepare_for_loso_dev\n",
    "\n",
    "if save_x is False:\n",
    "    resampled_clean_videos_images_features = None\n",
    "\n",
    "y, groups = prepare_for_loso_dev(\n",
    "    resampled_clean_videos_images_features,\n",
    "    labels,\n",
    "    clean_subjects,\n",
    "    clean_videos_images,\n",
    "    clean_subjects_videos_ground_truth_labels,\n",
    "    k,\n",
    "    save_x,\n",
    "    expression_type,\n",
    "    dataset_dir,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_preds is False:\n",
    "    from training_dev import train\n",
    "\n",
    "    preds = train(\n",
    "        dataset_dir,\n",
    "        clean_subjects,\n",
    "        image_size=image_size,\n",
    "        y=y,\n",
    "        expression_type=expression_type,\n",
    "        model_name=model_name,\n",
    "        train_or_not=True,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        preds_path=preds_path,\n",
    "    )\n",
    "else:\n",
    "    with open(preds_path, \"rb\") as pkl_file:\n",
    "        preds = _pickle.load(pkl_file)\n",
    "        pkl_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_preds is True:\n",
    "    with open(preds_path, \"wb\") as pkl_file:\n",
    "        _pickle.dump(preds, pkl_file)\n",
    "        pkl_file.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotting and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1/29 is in process.\n",
      "0 video(s) have been processed.\n",
      "The current video be processed: subject 006, video 1\n",
      "The current video be processed: subject 006, video 2\n",
      "The current video be processed: subject 006, video 3\n",
      "The current video be processed: subject 006, video 5\n",
      "\n",
      "True Positive: 1, False Posive: 42, False Negative: 10\n",
      "Precision = 0.023255813953488594, Recall =0.09090909090909113, F1-Score = 0.037037037037037555\n",
      "Split 1/29 is processed.\n",
      "\n",
      "Split 2/29 is in process.\n",
      "4 video(s) have been processed.\n",
      "The current video be processed: subject 007, video 3\n",
      "The current video be processed: subject 007, video 4\n",
      "The current video be processed: subject 007, video 5\n",
      "The current video be processed: subject 007, video 6\n",
      "The current video be processed: subject 007, video 7\n",
      "\n",
      "True Positive: 3, False Posive: 63, False Negative: 18\n",
      "Precision = 0.04545454545454568, Recall =0.14285714285714307, F1-Score = 0.06896551724137981\n",
      "Split 2/29 is processed.\n",
      "\n",
      "Split 3/29 is in process.\n",
      "9 video(s) have been processed.\n",
      "The current video be processed: subject 009, video 2\n",
      "The current video be processed: subject 009, video 3\n",
      "\n",
      "True Positive: 3, False Posive: 68, False Negative: 22\n",
      "Precision = 0.042253521126760785, Recall =0.12000000000000022, F1-Score = 0.06250000000000049\n",
      "Split 3/29 is processed.\n",
      "\n",
      "Split 4/29 is in process.\n",
      "11 video(s) have been processed.\n",
      "The current video be processed: subject 010, video 2\n",
      "The current video be processed: subject 010, video 4\n",
      "\n",
      "True Positive: 3, False Posive: 96, False Negative: 26\n",
      "Precision = 0.030303030303030526, Recall =0.10344827586206919, F1-Score = 0.04687500000000051\n",
      "Split 4/29 is processed.\n",
      "\n",
      "Split 5/29 is in process.\n",
      "13 video(s) have been processed.\n",
      "The current video be processed: subject 011, video 1\n",
      "The current video be processed: subject 011, video 2\n",
      "The current video be processed: subject 011, video 3\n",
      "The current video be processed: subject 011, video 4\n",
      "The current video be processed: subject 011, video 5\n",
      "The current video be processed: subject 011, video 6\n",
      "The current video be processed: subject 011, video 7\n",
      "\n",
      "True Positive: 4, False Posive: 169, False Negative: 45\n",
      "Precision = 0.023121387283237215, Recall =0.0816326530612247, F1-Score = 0.03603603603603655\n",
      "Split 5/29 is processed.\n",
      "\n",
      "Split 6/29 is in process.\n",
      "20 video(s) have been processed.\n",
      "The current video be processed: subject 012, video 3\n",
      "The current video be processed: subject 012, video 7\n",
      "\n",
      "True Positive: 6, False Posive: 183, False Negative: 46\n",
      "Precision = 0.031746031746031966, Recall =0.11538461538461561, F1-Score = 0.04979253112033246\n",
      "Split 6/29 is processed.\n",
      "\n",
      "Split 7/29 is in process.\n",
      "22 video(s) have been processed.\n",
      "The current video be processed: subject 013, video 1\n",
      "The current video be processed: subject 013, video 7\n",
      "\n",
      "True Positive: 6, False Posive: 198, False Negative: 52\n",
      "Precision = 0.029411764705882575, Recall =0.10344827586206919, F1-Score = 0.045801526717557765\n",
      "Split 7/29 is processed.\n",
      "\n",
      "Split 8/29 is in process.\n",
      "24 video(s) have been processed.\n",
      "The current video be processed: subject 014, video 1\n",
      "The current video be processed: subject 014, video 2\n",
      "The current video be processed: subject 014, video 3\n",
      "The current video be processed: subject 014, video 5\n",
      "The current video be processed: subject 014, video 6\n",
      "The current video be processed: subject 014, video 7\n",
      "\n",
      "True Positive: 9, False Posive: 256, False Negative: 60\n",
      "Precision = 0.03396226415094362, Recall =0.13043478260869587, F1-Score = 0.0538922155688628\n",
      "Split 8/29 is processed.\n",
      "\n",
      "Split 9/29 is in process.\n",
      "30 video(s) have been processed.\n",
      "The current video be processed: subject 015, video 5\n",
      "\n",
      "True Positive: 10, False Posive: 264, False Negative: 62\n",
      "Precision = 0.03649635036496372, Recall =0.13888888888888912, F1-Score = 0.057803468208093\n",
      "Split 9/29 is processed.\n",
      "\n",
      "Split 10/29 is in process.\n",
      "31 video(s) have been processed.\n",
      "The current video be processed: subject 016, video 7\n",
      "\n",
      "True Positive: 13, False Posive: 266, False Negative: 64\n",
      "Precision = 0.04659498207885327, Recall =0.16883116883116905, F1-Score = 0.07303370786516905\n",
      "Split 10/29 is processed.\n",
      "\n",
      "Split 11/29 is in process.\n",
      "32 video(s) have been processed.\n",
      "The current video be processed: subject 017, video 3\n",
      "The current video be processed: subject 017, video 6\n",
      "\n",
      "True Positive: 15, False Posive: 271, False Negative: 68\n",
      "Precision = 0.05244755244755267, Recall =0.18072289156626528, F1-Score = 0.08130081300813059\n",
      "Split 11/29 is processed.\n",
      "\n",
      "Split 12/29 is in process.\n",
      "34 video(s) have been processed.\n",
      "The current video be processed: subject 018, video 1\n",
      "The current video be processed: subject 018, video 3\n",
      "The current video be processed: subject 018, video 5\n",
      "The current video be processed: subject 018, video 7\n",
      "\n",
      "True Positive: 16, False Posive: 295, False Negative: 71\n",
      "Precision = 0.0514469453376208, Recall =0.1839080459770117, F1-Score = 0.08040201005025177\n",
      "Split 12/29 is processed.\n",
      "\n",
      "Split 13/29 is in process.\n",
      "38 video(s) have been processed.\n",
      "The current video be processed: subject 019, video 3\n",
      "The current video be processed: subject 019, video 4\n",
      "The current video be processed: subject 019, video 5\n",
      "\n",
      "True Positive: 17, False Posive: 306, False Negative: 73\n",
      "Precision = 0.05263157894736864, Recall =0.1888888888888891, F1-Score = 0.08232445520581165\n",
      "Split 13/29 is processed.\n",
      "\n",
      "Split 14/29 is in process.\n",
      "41 video(s) have been processed.\n",
      "The current video be processed: subject 020, video 1\n",
      "The current video be processed: subject 020, video 4\n",
      "The current video be processed: subject 020, video 7\n",
      "\n",
      "True Positive: 19, False Posive: 331, False Negative: 80\n",
      "Precision = 0.054285714285714506, Recall =0.19191919191919213, F1-Score = 0.0846325167037867\n",
      "Split 14/29 is processed.\n",
      "\n",
      "Split 15/29 is in process.\n",
      "44 video(s) have been processed.\n",
      "The current video be processed: subject 021, video 7\n",
      "\n",
      "True Positive: 19, False Posive: 337, False Negative: 82\n",
      "Precision = 0.05337078651685415, Recall =0.18811881188118834, F1-Score = 0.08315098468271385\n",
      "Split 15/29 is processed.\n",
      "\n",
      "Split 16/29 is in process.\n",
      "45 video(s) have been processed.\n",
      "The current video be processed: subject 022, video 2\n",
      "The current video be processed: subject 022, video 3\n",
      "The current video be processed: subject 022, video 4\n",
      "The current video be processed: subject 022, video 5\n",
      "\n",
      "True Positive: 21, False Posive: 346, False Negative: 85\n",
      "Precision = 0.057220708446866705, Recall =0.19811320754717004, F1-Score = 0.08879492600422884\n",
      "Split 16/29 is processed.\n",
      "\n",
      "Split 17/29 is in process.\n",
      "49 video(s) have been processed.\n",
      "The current video be processed: subject 023, video 1\n",
      "\n",
      "True Positive: 21, False Posive: 349, False Negative: 86\n",
      "Precision = 0.05675675675675698, Recall =0.19626168224299087, F1-Score = 0.08805031446540931\n",
      "Split 17/29 is processed.\n",
      "\n",
      "Split 18/29 is in process.\n",
      "50 video(s) have been processed.\n",
      "The current video be processed: subject 024, video 2\n",
      "\n",
      "True Positive: 21, False Posive: 352, False Negative: 87\n",
      "Precision = 0.05630026809651497, Recall =0.19444444444444467, F1-Score = 0.08731808731808784\n",
      "Split 18/29 is processed.\n",
      "\n",
      "Split 19/29 is in process.\n",
      "51 video(s) have been processed.\n",
      "The current video be processed: subject 025, video 4\n",
      "The current video be processed: subject 025, video 5\n",
      "The current video be processed: subject 025, video 6\n",
      "\n",
      "True Positive: 23, False Posive: 364, False Negative: 89\n",
      "Precision = 0.059431524547803836, Recall =0.20535714285714307, F1-Score = 0.09218436873747546\n",
      "Split 19/29 is processed.\n",
      "\n",
      "Split 20/29 is in process.\n",
      "54 video(s) have been processed.\n",
      "The current video be processed: subject 026, video 1\n",
      "The current video be processed: subject 026, video 2\n",
      "The current video be processed: subject 026, video 3\n",
      "The current video be processed: subject 026, video 5\n",
      "The current video be processed: subject 026, video 6\n",
      "The current video be processed: subject 026, video 7\n",
      "\n",
      "True Positive: 30, False Posive: 381, False Negative: 95\n",
      "Precision = 0.07299270072992722, Recall =0.2400000000000002, F1-Score = 0.11194029850746318\n",
      "Split 20/29 is processed.\n",
      "\n",
      "Split 21/29 is in process.\n",
      "60 video(s) have been processed.\n",
      "The current video be processed: subject 028, video 4\n",
      "\n",
      "True Positive: 31, False Posive: 383, False Negative: 97\n",
      "Precision = 0.07487922705314032, Recall =0.24218750000000022, F1-Score = 0.11439114391143962\n",
      "Split 21/29 is processed.\n",
      "\n",
      "Split 22/29 is in process.\n",
      "61 video(s) have been processed.\n",
      "The current video be processed: subject 030, video 1\n",
      "The current video be processed: subject 030, video 5\n",
      "\n",
      "True Positive: 31, False Posive: 394, False Negative: 100\n",
      "Precision = 0.07294117647058845, Recall =0.23664122137404603, F1-Score = 0.11151079136690698\n",
      "Split 22/29 is processed.\n",
      "\n",
      "Split 23/29 is in process.\n",
      "63 video(s) have been processed.\n",
      "The current video be processed: subject 031, video 3\n",
      "\n",
      "True Positive: 31, False Posive: 396, False Negative: 101\n",
      "Precision = 0.07259953161592528, Recall =0.23484848484848508, F1-Score = 0.11091234347048352\n",
      "Split 23/29 is processed.\n",
      "\n",
      "Split 24/29 is in process.\n",
      "64 video(s) have been processed.\n",
      "The current video be processed: subject 032, video 3\n",
      "The current video be processed: subject 032, video 4\n",
      "The current video be processed: subject 032, video 6\n",
      "\n",
      "True Positive: 32, False Posive: 408, False Negative: 106\n",
      "Precision = 0.07272727272727295, Recall =0.23188405797101472, F1-Score = 0.11072664359861642\n",
      "Split 24/29 is processed.\n",
      "\n",
      "Split 25/29 is in process.\n",
      "67 video(s) have been processed.\n",
      "The current video be processed: subject 033, video 1\n",
      "The current video be processed: subject 033, video 2\n",
      "\n",
      "True Positive: 32, False Posive: 440, False Negative: 111\n",
      "Precision = 0.06779661016949175, Recall =0.223776223776224, F1-Score = 0.104065040650407\n",
      "Split 25/29 is processed.\n",
      "\n",
      "Split 26/29 is in process.\n",
      "69 video(s) have been processed.\n",
      "The current video be processed: subject 034, video 3\n",
      "The current video be processed: subject 034, video 7\n",
      "\n",
      "True Positive: 32, False Posive: 456, False Negative: 114\n",
      "Precision = 0.0655737704918035, Recall =0.21917808219178103, F1-Score = 0.10094637223974814\n",
      "Split 26/29 is processed.\n",
      "\n",
      "Split 27/29 is in process.\n",
      "71 video(s) have been processed.\n",
      "The current video be processed: subject 035, video 1\n",
      "The current video be processed: subject 035, video 4\n",
      "The current video be processed: subject 035, video 5\n",
      "The current video be processed: subject 035, video 6\n",
      "The current video be processed: subject 035, video 7\n",
      "\n",
      "True Positive: 34, False Posive: 479, False Negative: 121\n",
      "Precision = 0.0662768031189086, Recall =0.21935483870967765, F1-Score = 0.10179640718562925\n",
      "Split 27/29 is processed.\n",
      "\n",
      "Split 28/29 is in process.\n",
      "76 video(s) have been processed.\n",
      "The current video be processed: subject 036, video 7\n",
      "\n",
      "True Positive: 34, False Posive: 490, False Negative: 122\n",
      "Precision = 0.06488549618320633, Recall =0.21794871794871817, F1-Score = 0.1000000000000005\n",
      "Split 28/29 is processed.\n",
      "\n",
      "Split 29/29 is in process.\n",
      "77 video(s) have been processed.\n",
      "The current video be processed: subject 037, video 3\n",
      "The current video be processed: subject 037, video 4\n",
      "\n",
      "True Positive: 35, False Posive: 496, False Negative: 124\n",
      "Precision = 0.06591337099811698, Recall =0.22012578616352224, F1-Score = 0.10144927536231936\n",
      "Split 29/29 is processed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from functions import *\n",
    "\n",
    "metric_fn, result_dict = spot_and_evaluate(\n",
    "    preds,\n",
    "    clean_subjects_videos_ground_truth_labels,\n",
    "    clean_videos_images,\n",
    "    clean_subjects,\n",
    "    clean_subjects_videos_code,\n",
    "    k,\n",
    "    p=0.60,\n",
    "    show_plot_or_not=False,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 35, False Posive: 496, False Negative: 124\n",
      "Final Precision = 0.06591337099811698,\n",
      "Final Recall =0.22012578616352224,\n",
      "Final F1-Score = 0.10144927536231936\n",
      "\n",
      "Highest Precision = 0.07487922705314032,\n",
      "Highest Recall =0.24218750000000022,\n",
      "Highest F1-Score = 0.11439114391143962\n"
     ]
    }
   ],
   "source": [
    "from evaluation import final_evaluate\n",
    "\n",
    "final_evaluate(metric_fn, result_dict)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameters | Value | Value \n",
    "| --- | --- | ---\n",
    "| model | 3D-CNN | SOFTNet \n",
    "| epochs | | \n",
    "| batch_size | | 48  \n",
    "| learning_rate | | 0.0005\n",
    "| True Positive | | 38\n",
    "| False Positive | | 303\n",
    "| False Negative | | 121\n",
    "| Precision | | 0.1114\n",
    "| Recall | | 0.3188 | 0.2309\n",
    "| F1-Score | 0.0466 | 0.1520\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameters | Value | Value | Value | Value\n",
    "| --- | --- | --- | --- | ---\n",
    "| model | Swin-T | Swin-T | SL-Swin-T | SL-Swin-T_2\n",
    "| epochs | 25 (4350 m) | 25 (4350 m) | 25 (7399 m) | 25 (7400 m)\n",
    "| batch_size | 48 | 48 | 48 | 48\n",
    "| p | 0.57 | 0.60 | 0.59 | 0.60\n",
    "| True Positive | 37 | 29 | 26 | 33\n",
    "| False Positive | 518 | 468 | 409 | 440\n",
    "| False Negative | 122 | 130 | 133 | 126\n",
    "| Precision | 0.0667 | 0.0583 | 0.0597 | 0.0698\n",
    "| Recall | 0.2327 | 0.1823 | 0.1635 | 0.2075\n",
    "| F1-Score | 0.1036 | 0.0884 | 0.0875 | 0.1044\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameters | Value | Value | Value | Value\n",
    "| --- | --- | --- | --- | ---\n",
    "| model | ViT-B | SL-ViT | S-Swin-T | L-Swin-T\n",
    "| epochs | 25 (15605 m) | 25 ( m) | 25 (4827 m) | 25 (6960 m)\n",
    "| batch_size | 48 | 48 | 48 | 48\n",
    "| p | 0.57 | 0.60 | 0.59 | 0.60\n",
    "| True Positive |  |  |  | \n",
    "| False Positive |  |  |  | \n",
    "| False Negative |  |  |  | \n",
    "| Precision |  |  |  | \n",
    "| Recall |  |  |  | \n",
    "| F1-Score |  |  |  | \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation Study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " p | TP | FP | FN | Precision | Recall | F1-Score\n",
      "0.01 | 94 | 2571 | 65 | 0.0353 | 0.5912 | 0.0666 |\n",
      "0.02 | 94 | 2487 | 65 | 0.0364 | 0.5912 | 0.0686 |\n",
      "0.03 | 91 | 2403 | 68 | 0.0365 | 0.5723 | 0.0686 |\n",
      "0.04 | 89 | 2316 | 70 | 0.0370 | 0.5597 | 0.0694 |\n",
      "0.05 | 89 | 2253 | 70 | 0.0380 | 0.5597 | 0.0712 |\n",
      "0.06 | 89 | 2188 | 70 | 0.0391 | 0.5597 | 0.0731 |\n",
      "0.07 | 89 | 2121 | 70 | 0.0403 | 0.5597 | 0.0751 |\n",
      "0.08 | 88 | 2057 | 71 | 0.0410 | 0.5535 | 0.0764 |\n",
      "0.09 | 87 | 1995 | 72 | 0.0418 | 0.5472 | 0.0776 |\n",
      "0.10 | 84 | 1924 | 75 | 0.0418 | 0.5283 | 0.0775 |\n",
      "0.11 | 84 | 1862 | 75 | 0.0432 | 0.5283 | 0.0798 |\n",
      "0.12 | 82 | 1806 | 77 | 0.0434 | 0.5157 | 0.0801 |\n",
      "0.13 | 82 | 1756 | 77 | 0.0446 | 0.5157 | 0.0821 |\n",
      "0.14 | 80 | 1697 | 79 | 0.0450 | 0.5031 | 0.0826 |\n",
      "0.15 | 78 | 1656 | 81 | 0.0450 | 0.4906 | 0.0824 |\n",
      "0.16 | 76 | 1615 | 83 | 0.0449 | 0.4780 | 0.0822 |\n",
      "0.17 | 73 | 1572 | 86 | 0.0444 | 0.4591 | 0.0809 |\n",
      "0.18 | 72 | 1537 | 87 | 0.0447 | 0.4528 | 0.0814 |\n",
      "0.19 | 70 | 1508 | 89 | 0.0444 | 0.4403 | 0.0806 |\n",
      "0.20 | 70 | 1464 | 89 | 0.0456 | 0.4403 | 0.0827 |\n",
      "0.21 | 70 | 1434 | 89 | 0.0465 | 0.4403 | 0.0842 |\n",
      "0.22 | 69 | 1403 | 90 | 0.0469 | 0.4340 | 0.0846 |\n",
      "0.23 | 68 | 1369 | 91 | 0.0473 | 0.4277 | 0.0852 |\n",
      "0.24 | 66 | 1328 | 93 | 0.0473 | 0.4151 | 0.0850 |\n",
      "0.25 | 65 | 1296 | 94 | 0.0478 | 0.4088 | 0.0855 |\n",
      "0.26 | 64 | 1259 | 95 | 0.0484 | 0.4025 | 0.0864 |\n",
      "0.27 | 64 | 1232 | 95 | 0.0494 | 0.4025 | 0.0880 |\n",
      "0.28 | 62 | 1206 | 97 | 0.0489 | 0.3899 | 0.0869 |\n",
      "0.29 | 62 | 1181 | 97 | 0.0499 | 0.3899 | 0.0884 |\n",
      "0.30 | 60 | 1158 | 99 | 0.0493 | 0.3774 | 0.0871 |\n",
      "0.31 | 59 | 1129 | 100 | 0.0497 | 0.3711 | 0.0876 |\n",
      "0.32 | 58 | 1104 | 101 | 0.0499 | 0.3648 | 0.0878 |\n",
      "0.33 | 58 | 1075 | 101 | 0.0512 | 0.3648 | 0.0898 |\n",
      "0.34 | 58 | 1050 | 101 | 0.0523 | 0.3648 | 0.0916 |\n",
      "0.35 | 58 | 1022 | 101 | 0.0537 | 0.3648 | 0.0936 |\n",
      "0.36 | 57 | 993 | 102 | 0.0543 | 0.3585 | 0.0943 |\n",
      "0.37 | 56 | 966 | 103 | 0.0548 | 0.3522 | 0.0948 |\n",
      "0.38 | 56 | 945 | 103 | 0.0559 | 0.3522 | 0.0966 |\n",
      "0.39 | 55 | 922 | 104 | 0.0563 | 0.3459 | 0.0968 |\n",
      "0.40 | 54 | 896 | 105 | 0.0568 | 0.3396 | 0.0974 |\n",
      "0.41 | 54 | 875 | 105 | 0.0581 | 0.3396 | 0.0993 |\n",
      "0.42 | 53 | 853 | 106 | 0.0585 | 0.3333 | 0.0995 |\n",
      "0.43 | 51 | 819 | 108 | 0.0586 | 0.3208 | 0.0991 |\n",
      "0.44 | 51 | 795 | 108 | 0.0603 | 0.3208 | 0.1015 |\n",
      "0.45 | 51 | 777 | 108 | 0.0616 | 0.3208 | 0.1033 |\n",
      "0.46 | 49 | 756 | 110 | 0.0609 | 0.3082 | 0.1017 |\n",
      "0.47 | 48 | 734 | 111 | 0.0614 | 0.3019 | 0.1020 |\n",
      "0.48 | 46 | 720 | 113 | 0.0601 | 0.2893 | 0.0995 |\n",
      "0.49 | 46 | 705 | 113 | 0.0613 | 0.2893 | 0.1011 |\n",
      "0.50 | 45 | 681 | 114 | 0.0620 | 0.2830 | 0.1017 |\n",
      "0.51 | 44 | 653 | 115 | 0.0631 | 0.2767 | 0.1028 |\n",
      "0.52 | 44 | 642 | 115 | 0.0641 | 0.2767 | 0.1041 |\n",
      "0.53 | 43 | 623 | 116 | 0.0646 | 0.2704 | 0.1042 |\n",
      "0.54 | 40 | 598 | 119 | 0.0627 | 0.2516 | 0.1004 |\n",
      "0.55 | 39 | 577 | 120 | 0.0633 | 0.2453 | 0.1006 |\n",
      "0.56 | 38 | 554 | 121 | 0.0642 | 0.2390 | 0.1012 |\n",
      "0.57 | 37 | 538 | 122 | 0.0643 | 0.2327 | 0.1008 |\n",
      "0.58 | 36 | 525 | 123 | 0.0642 | 0.2264 | 0.1000 |\n",
      "0.59 | 35 | 511 | 124 | 0.0641 | 0.2201 | 0.0993 |\n",
      "0.60 | 35 | 496 | 124 | 0.0659 | 0.2201 | 0.1014 |\n",
      "0.61 | 33 | 474 | 126 | 0.0651 | 0.2075 | 0.0991 |\n",
      "0.62 | 31 | 461 | 128 | 0.0630 | 0.1950 | 0.0952 |\n",
      "0.63 | 31 | 447 | 128 | 0.0649 | 0.1950 | 0.0973 |\n",
      "0.64 | 31 | 429 | 128 | 0.0674 | 0.1950 | 0.1002 |\n",
      "0.65 | 31 | 415 | 128 | 0.0695 | 0.1950 | 0.1025 |\n",
      "0.66 | 30 | 403 | 129 | 0.0693 | 0.1887 | 0.1014 |\n",
      "0.67 | 30 | 388 | 129 | 0.0718 | 0.1887 | 0.1040 |\n",
      "0.68 | 29 | 369 | 130 | 0.0729 | 0.1824 | 0.1041 |\n",
      "0.69 | 28 | 352 | 131 | 0.0737 | 0.1761 | 0.1039 |\n",
      "0.70 | 28 | 336 | 131 | 0.0769 | 0.1761 | 0.1071 |\n",
      "0.71 | 27 | 322 | 132 | 0.0774 | 0.1698 | 0.1063 |\n",
      "0.72 | 27 | 313 | 132 | 0.0794 | 0.1698 | 0.1082 |\n",
      "0.73 | 25 | 297 | 134 | 0.0776 | 0.1572 | 0.1040 |\n",
      "0.74 | 25 | 280 | 134 | 0.0820 | 0.1572 | 0.1078 |\n",
      "0.75 | 25 | 269 | 134 | 0.0850 | 0.1572 | 0.1104 |\n",
      "0.76 | 24 | 262 | 135 | 0.0839 | 0.1509 | 0.1079 |\n",
      "0.77 | 22 | 246 | 137 | 0.0821 | 0.1384 | 0.1030 |\n",
      "0.78 | 21 | 234 | 138 | 0.0824 | 0.1321 | 0.1014 |\n",
      "0.79 | 21 | 227 | 138 | 0.0847 | 0.1321 | 0.1032 |\n",
      "0.80 | 20 | 217 | 139 | 0.0844 | 0.1258 | 0.1010 |\n",
      "0.81 | 20 | 207 | 139 | 0.0881 | 0.1258 | 0.1036 |\n",
      "0.82 | 19 | 197 | 140 | 0.0880 | 0.1195 | 0.1013 |\n",
      "0.83 | 19 | 187 | 140 | 0.0922 | 0.1195 | 0.1041 |\n",
      "0.84 | 18 | 180 | 141 | 0.0909 | 0.1132 | 0.1008 |\n",
      "0.85 | 17 | 168 | 142 | 0.0919 | 0.1069 | 0.0988 |\n",
      "0.86 | 17 | 160 | 142 | 0.0960 | 0.1069 | 0.1012 |\n",
      "0.87 | 17 | 156 | 142 | 0.0983 | 0.1069 | 0.1024 |\n",
      "0.88 | 16 | 148 | 143 | 0.0976 | 0.1006 | 0.0991 |\n",
      "0.89 | 16 | 141 | 143 | 0.1019 | 0.1006 | 0.1013 |\n",
      "0.90 | 15 | 135 | 144 | 0.1000 | 0.0943 | 0.0971 |\n",
      "0.91 | 15 | 126 | 144 | 0.1064 | 0.0943 | 0.1000 |\n",
      "0.92 | 14 | 118 | 145 | 0.1061 | 0.0881 | 0.0962 |\n",
      "0.93 | 14 | 112 | 145 | 0.1111 | 0.0881 | 0.0982 |\n",
      "0.94 | 14 | 106 | 145 | 0.1167 | 0.0881 | 0.1004 |\n",
      "0.95 | 13 | 97 | 146 | 0.1182 | 0.0818 | 0.0967 |\n",
      "0.96 | 13 | 92 | 146 | 0.1238 | 0.0818 | 0.0985 |\n",
      "0.97 | 12 | 86 | 147 | 0.1224 | 0.0755 | 0.0934 |\n",
      "0.98 | 12 | 78 | 147 | 0.1333 | 0.0755 | 0.0964 |\n",
      "0.99 | 12 | 73 | 147 | 0.1412 | 0.0755 | 0.0984 |\n"
     ]
    }
   ],
   "source": [
    "from functions import *\n",
    "\n",
    "ablation_dict = ablation_study_p_dev(\n",
    "    preds,\n",
    "    clean_subjects_videos_ground_truth_labels,\n",
    "    clean_videos_images,\n",
    "    clean_subjects,\n",
    "    clean_subjects_videos_code,\n",
    "    k,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6696e3028ae55fa5be357812587f73779dfb157cc851dab91c4ca8ffd3c7a806"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
